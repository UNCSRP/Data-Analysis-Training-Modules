---
title: "Data Organization Basics"
output:
  html_document: default
---

This training module was developed by Dr. Kyle R. Roell and Dr. Julia E. Rager

Fall 2021

```{r , include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Introduction to Training Module

Data within the fields of exposure science, toxicology, and public health are very rarely prepared and ready for all statistical analyses/visualization code. The beginning of almost any scripted analysis includes important formatting steps. These steps largely encompass data organization, manipulation, and other steps in preparation for actual statistical analyses/visualizations. Data organization and manipulation generally refers to organizing and formatting data in a way that makes it easier to read and work with. This can be done through several approaches, including:

+ Base R operations and functions, or
+ A collection of packages (and philosophy) known as [Tidyverse](https://www.tidyverse.org).

In this training tutorial we will go over some of the most common ways you can organize and manipulate data, including:

+ Merging data
+ Filtering and subsetting data
+ Melting and casting data

These approaches will first be taught using the basic operations and functions in R. Then, the exact same approaches will be taught using the Tidyverse package and associated functions and syntax.

These data manipulation and organization methods are demonstrated using an example environmentally relevant human cohort dataset. This cohort was generated by creating data distributions randomly pulled from our previously published cohorts, resulting in a bespoke dataset for these training purposes with associated demographic data and variable environmental exposure metrics from metal levels obtained using sources of drinking water and human urine samples.



#### Set your working directory
In preparation, first let's set our working directory to the folderpath that contains our input files
```{r, eval=FALSE, echo=TRUE}
setwd("/filepath to where your input files are")
```
Note that in macOS, filepaths use "/" as folder separaters; whereas in PCs, filepaths use "\".


#### Importing example datasets

Then let's read in our example datasets
```{r}
demo.data <- read.csv("Module1_2/Module1_2_DemographicData.csv")
chem.data <- read.csv("Module1_2/Module1_2_ChemicalData.csv")
```


#### Viewing example datasets
Let's see what these datasets look like, starting with the chemical measures:
```{r}
dim(chem.data)
```
The chemical measurement dataset includes 200 rows x 7 columns


```{r}
chem.data[1:10,1:7]
```
These data are organized according to subject ID (first column), followed by measures of:

+ DWAs (drinking water arsenic levels in µg/L)
+ DWCd (drinking water cadmium levels in µg/L)
+ DWCr (drinking water chromium levels in µg/L)
+ UAs (urinary arsenic levels in µg/L)
+ UCd (urinary cadmium levels in µg/L)
+ UCr (urinary chromium levels in µg/L)


Now let's view the demographic data:
```{r}
dim(demo.data)
```
The subject demographic dataset includes 200 rows x 6 columns

```{r}
demo.data[1:10,1:6]
```
These data are organized according to subject ID (first column) followed by the following subject information:

+ BMI (body mass index)
+ MAge (maternal age, years)
+ MEdu (maternal education, 1= "less than high school"; 2= "high school or some college"; 3= "college or greater")
+ BW (body weight, grams)
+ GA (gestational age, week)




## Data Manipulation using Base R

#### Merging Data using Base R Syntax
Merging datasets represents the joining together of two or more datasets, while connecting the datasets using a common identifier (generally some sort of ID). This is useful if you have multiple datasets describing different aspects of the study, different variables, or different measures across the same samples. Samples could correspond to the same study participants, animals, cell culture samples, environmental media samples, etc, depending on the study design. In the current example, we will be joining human demographic data and environmental metals exposure data collected from drinking water and human urine samples.

Let's start by merging the example demographic data with the chemical measurement data using the base R function of "merge". To learn more about this function, you can type the following:
```{r}
?merge
```
which brings up helpful information in the R console


To merge these datasets using the merge function, use the following code:
```{r}
# Note that we specify to merge these datasets by their shared ID column
full.data <- merge(demo.data, chem.data, by="ID") 
dim(full.data) 
```
This merged dataframe contains 200 rows x 12 columns

Viewing this merged dataframe
```{r}
full.data[1:10, 1:12]
```
We can see that the merge function retained the first column in each original dataframe (ID), though did not replicate it since it was used as the identifier to merge off of. All other columns include their original data, just merged together by the IDs in the first column.


These datasets were actually quite easy to merge, since they had the same exact column identifier and number of rows. You can edit your script to include more specifics in instances when these may differ across datasets that you would like to merge. For example:
```{r}
full.data <- merge(demo.data, chem.data, by.x="ID", by.y="ID") 
# This option allows you to edit the column header text that is used in each 
# dataframe. Here, these are still the same "ID", but you can see that adding 
# this script allows you to specify instances when differ header text is used.
```



#### Filtering and Subsetting Data using Base R Syntax

Filtering and subsetting data are useful tools when you need to focus your dataset to highlight data you are interested in analyzing downstream. These could represent, for example, specific samples or participants that meet certain criteria that you are interested in evaluating. It is also useful for simply removing particular variables or samples from dataframes as you are working through your script. These methods are illustrated here.

For this example, let's first define a vector of columns that we want to keep in our analysis
```{r}
subset.columns <- c("BMI", "MAge", "MEdu")
subset.columns
```


Now we can simply subset our data using those columns
```{r}
# Subsetting the data by selecting the columns represented in the defined 
# 'subset.columns' vector
subset.data1 <- full.data[,subset.columns] 

# Viewing the top of this subsetted dataframe
head(subset.data1) 
```

Conversely, if we want to remove all columns except those that we are interested in within the 'subset.columns' vector, we can write the code as follows (to achieve the same results).

Note that we have to first create a vector of TRUE/FALSE's here to execute the removal script written below:
```{r}
# First specify which columns we would like to remove
remove.columns <- colnames(full.data) %in% subset.columns 

# Viewing this new vector
remove.columns 
```
This creates a vector of TRUE/FALSE's denoting whether or not each column is included in the 'subset.columns' vector


Now we can subset our dataset. Here, we decide to keep those that are labeled 'FALSE' in the remove.columns vector. This will remove the columns that are NOT contained in the subset.columns vector
```{r}
subset.data2 <- full.data[,!remove.columns]

# Viewing the top of this dataframe
head(subset.data2)
```


We can also easily subset data based on row numbers. For example, to keep only the first 100 rows:
```{r}
subset.data3 <- full.data[1:100,]

# Viewing the dimensions of this new dataframe
dim(subset.data3)
```

To remove the first 100 rows:
```{r}
subset.data4 <- full.data[-c(1:100),]

# Viewing the dimensions of this new dataframe
dim(subset.data4)
```


To filter data using **conditional statements**:
```{r}
subset.data5 <- full.data[which(full.data$BMI > 25 & full.data$MAge > 31),]

# Viewing the top of this new dataframe
head(subset.data5)
```


Filtering data based on conditions can also be done using the subset function:
```{r}
subset.data6 <- subset(full.data, BMI > 25 & MAge > 31)
```


Additionally, we can subset and select specific columns we would like to keep, using 'select' within the subset function:
```{r}
subset.data7 <- subset(full.data, BMI < 22 | BMI > 27, 
                       select=c("BMI", "MAge", "MEdu"))
```

For more information on the subset function, see its associated [RDocumentation website](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/subset).



#### Melting and Casting Data using Base R Syntax
Melting and casting refers to the conversion of data to "long" or "wide" form. You will often see data within the environmental health field in wide format; though long format is necessary for some procedures, such as plotting with [ggplot2](https://ggplot2.tidyverse.org).

Here, we'll illustrate some example script to melt and cast data using the [reshape2 package](https://www.rdocumentation.org/packages/reshape2/versions/1.4.4).
Let's first load the reshape2 library:
```{r}
library(reshape2)
```

Using the fully merged dataframe, let's remind ourselves what these data look like in the current dataframe format:
```{r}
head(full.data)
```
These data are represented by single subject identifiers listed as unique IDs per row, with associated environmental measures and demographic data organized across the columns. Thus, this dataframe is currently in **wide (also known as casted)** format.

Let's convert this dataframe to **long (also known as melted)** format:
```{r}
# Here, we are saying that we want a row for each unique 
# sample ID - variable measure pair
full.melted <- melt(full.data, id="ID") 

# Viewing this new dataframe
head(full.melted) 
```
You can see here that each measure that was originally contained as a unique column has been reoriented, such that the original column header is now listed throughout the second column labeled "variable". Then, the third column contains the value of this variable.

Let's see an example view of the middle of this new dataframe
```{r}
full.melted[1100:1110,1:3]
```
Here, we can see a different variable (DWAs) now being listed. This continues throughout the entire dataframe, which has the following dimensions:
```{r}
dim(full.melted)
```
Thus, this dataframe is clearly melted, in long format.


Let's now re-cast this dataframe back into wide format using the 'dcast' function

```{r}
# Here, we are telling the dcast 
# function to give us a sample (ID) for every variable in the column labeled 'variable'. 
# Then it automatically fills the dataframe with values from the 'value' column
full.cast <- dcast(full.melted, ID ~ variable) 
head(full.cast)

```
Here, we can see that this dataframe is back in its original casted (or wide) format.



## Introduction to Tidyverse

[Tidyverse](https://www.tidyverse.org) is a collection of packages that are commonly used to more efficiently organize and manipulate datasets in R. This collection of packages has its own specific type of syntax, dataset and formatting protocols that slightly differ from the Base R functions. Here, we will carry out all the of the same data organization exercises described above using Tidyverse.


#### Downloading and Loading the Tidyverse Package

If you don't have tidyverse already installed, you will need to install it using:
```{r, warnings=F, message=F}
if(!require(tidyverse)) install.packages("tidyverse")
```

And then load the tidyverse package using:
```{r, warnings=F, message=F}
library(tidyverse)
```


#### Merging Data using Tidyverse Syntax

To merge the same example dataframes using tidyverse, you can run the following script:
```{r}
full.data.tidy <- inner_join(demo.data, chem.data, by="ID")
# Note, for future scripting purposes, we can still merge with different IDs 
# using: by = c("ID.Demo"="ID.Chem")

head(full.data.tidy)
```


#### Filtering and Subsetting Data using Tidyverse Syntax

To subset columns in tidyverse, run the following:
```{r}
subset.tidy1 = full.data.tidy %>% select(all_of(subset.columns))
head(subset.tidy1)
```


Note that you can also include column identifiers that may get dropped in the subsetting vector here:
```{r}
# Note that we're including a 'fake' column here 'NotAColName' to illustrate 
# how to incorporate additional columns; though this column gets dropped in 
# the next line of code
subset.columns2 <- c(subset.columns, "NotAColName")

# Viewing this new vector
subset.columns2
```


```{r}
subset.tidy2 <- full.data.tidy %>% select(any_of(subset.columns2))

# Viewing the top of this new dataframe
head(subset.tidy2) 
```
Note that the 'fake' column 'NotAColName' gets automatically dropped here


To remove columns using tidyverse, you can run the following:
```{r, warnings=F, message=F}
# Removing columns
subset.tidy3 <- full.data.tidy %>% select(-subset.columns)

# Viewing this new dataframe
head(subset.tidy3) 
```

Subsetting rows using tidyverse:
```{r}
# Selecting to retain the first 100 rows
subset.tidy4 <- full.data.tidy %>% slice(1:100) 
dim(subset.tidy4)
```


```{r}
# Selecting to remove the first 100 rows
subset.tidy5 <- full.data.tidy %>% slice(-c(1:100))
dim(subset.tidy5)
```


Filtering data based on conditional statements using tidyverse:
```{r}
subset.tidy6 <- full.data.tidy %>% filter(BMI > 25 & MAge > 31)
dim(subset.tidy6)
```


Another example of a conditional statement that can be used to filter data:
```{r}
subset.tidy7 <- full.data.tidy %>% filter(BMI > 25 & MAge > 31) %>% select(BMI, MAge, MEdu)
```




#### Melting and Casting Data using Tidyverse Syntax
To melt and cast data in tidyverse, you can use the 'pivot' functions (i.e., 'pivot_longer' or 'pivot_wider'). These are exemplified below.

Melting to long format using tidyverse:
```{r}
full.pivotlong <- full.data.tidy %>% pivot_longer(-ID, names_to = "var", values_to = "value")
head(full.pivotlong, 15)
```

Casting to wide format using tidyverse:
```{r}
full.pivotwide <- full.pivotlong %>% pivot_wider(names_from = "var", values_from="value")
head(full.pivotwide)
```


## Concluding Remarks
Together, this training module provides introductory level information on the basics of data organization in R. The important data organization / manipulation methods of merging, filtering, subsetting, melting, and casted are presented on an environmentally relevant dataset.
 
